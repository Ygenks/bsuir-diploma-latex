\sectioncentered*{Введение}
\addcontentsline{toc}{section}{Введение}
\label{sec:intro}


Решение многих задач в науке и инженерии требует обработки различного рода данных, одним из которых являются изображения.
Задачами обработки изображений занимается целая наука --- Цифровая Обработка Сигналов(ЦОС),
изображения в которой рассматриваются как особый класс многомерных сигналов.

Высокая стоимость вычислительной техники в 60--70-е годы ограничивала применение
цифровых методов обработки сферами национальной безопасности, медициной, исследованием космоса.
Появление персональных компьютеров дало толчок в развитии ЦОС --- конечные пользователи
получили возможность решать задачи связанные с обработкой сигналов прямо на домашнем ПК,
при помощи различных подходов.

Обработка изображений в контексте ЦОС несет в себе ряд особенностей.
Во-первых, изображения характеризуются изменением пространственных параметров, тогда как звуковые сигналы описываются изменением временных параметров.
Во-вторых, объёмы информации, содержащейся в изображениях, очень велики.
Например, видеопоток несжатого RGB видео
с разрешением 1280х720 пикселей и частотой 50 кадров в секунду
занимает порядка $ 1280 \cdot 720 \cdot 3 \cdot 50 = 138,24 $ МБ памяти, когда как одна
секунда двуканального аудиосигнала с частотой дискретизации 44100 Гц
занимает $ 44100 \cdot 2 = 0,0882 $ МБ, что в 1567 раз больше. В-третьих, при оценке качества
изображения субъективная оценка доминирует над объективными критериями.

Несмотря на активное развитие рынка систем обработки видео, достаточно сложно найти
универсальную и модульную систему позволяющую обрабатывать видео высокого разрешения.
Существующие аппаратные реализации, как правило, <<заточены>> под решение одной конкретной задачи,
что делает практически невозможным переиспользование системы в случае смены условий решаемой проблемы.
Системы основанные на программной обработке до сих пор не могут обеспечить достаточной скорости, и подходят исключительно для видео с низким фреймрейтом или разрешением. % Ссылка

% Ещё один абзац

Целью данного дипломного проекта является разработка аппаратной системы обработки
видеопотока, основными особенностями которой являются модульность и поддержка
обработки видео выского разрешения. Модульность даёт возможность стороннему
разработчику дополнять поток обработки видео необходимыми блоками.
Поддержка видео выского разрешения становится всё более актуальной:
большинство современных потребительских медиа устройств гарантированно
поддерживают съёмку видео в разрешении 1920x1080 и выше. % Надо дать какую то ссылку


В соответствии с целью были поставлены следующие задачи:
\begin{itemize}
  \item обзор подходов к построению систем обработки видео;
  \item обзор конкурентных решений в рамках выбранного подхода;
  \item выбор необходимых блоков для проектирования системы;
  \item разработка структурной схемы;
  \item реализация проекта в САПР;
  \item разработка конфигурационного кода для управления системой.
\end{itemize}



% Всё ниже в обзор
Современные методы обработки изображений делятся на две категории: программная и аппаратная обработка.

Программная обработка производится на базе центрального проессора (CPU) и отличается высокой эффективностью
при использовании последовательных алгоритмов. В задачах с высоким Data Level Parallelism по обработке гомогенных данных
центральный процессор значительно проигрывает более специализированным решениям,
из-за малого количества SIMD блоков для параллельной обработки данных.

Комбинация программных и аппаратных подходов лежит в основе обработки изображений на графическом процессоре (GPU).
Связка графического процессора и SDK для его программирования образует GPGPU (General-Purpose computing for GPU).
GPGPU основна на прицнипе SIMT, основанный на разделении задачи на несколько подзадач того же типа, но меньшего размера,
решаемые каждым потоком GPU по отдельности.
Такой подход является удачной комбинацией скорости разработки программы и специализации графического процессора
на параллельной обработке данных.
Однако есть и существенные ограничения.
Латентность при обработке изображений на GPU слабодетерменирована, что усложняет использование GPGPU
в системах реального времени. % [[https://indico.cern.ch/event/390748/contributions/1825182/attachments/1281597/1904188/CR_1_63.pdf][ссылка]].
Отсутствует выбор периферийного интерфейса -- на момент написания,
графический процессоры подключаются исключительно по PCIe, сильно ограничивая перечень устройств.
Соотношение производительности на ватт затрудняет применение во встраиваемых системах с автономным питанием % [[http://www.gstitt.ece.ufl.edu/courses/fall11/eel4930_5934/reading/sliding_window_fpga12.pdf][ссылка]].

ASIC, как наиболее специализированное на конкретной задаче решение,
выполняет обработку за минимально возможное время и с минимальным энергопотреблением.
Разработка специализированной интегральной схемы связана с существенными затратами
на проектирование -- окупаемость наступает лишь при выпуске партиями в несколько сотен тысяч единиц,
исключая возможность применения технологии малыми и средними предприятиями. % [[http://anysilicon.com/fpga-vs-asic-choose/][ссылка]]

Применение FPGA позволяет достичь баланса между производительностью и конфигурируемостью конечного решения.
По сравнению с ASIC единовременные затраты на проектирование на несколько порядков ниже,
что идеально подходит для прототипирования и мелкосерийного производства.% [[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.458.4752&rep=rep1&type=pdf][ссылка]]
В отличие от GPU малое энергопотребление и небольшие размеры решений на FPGA прекрасно подходят
для встраиваемых систем. % [[http://www.bertendsp.com/pdf/whitepaper/BWP001_GPU_vs_FPGA_Performance_Comparison_v1.0.pdf][ссылка]]
Последовательные алгоритмы, непригодные для реализации на GPU, могут выполняться
на интегрированом CPU или soft core процессоре, заметно упрощая передачу данных
между последовательным и параллельным вычислителем, решая подобную задачу
для связки GPU и CPU.

В лул информационных технологий появляются огромные массивы данных, которые можно и нужно уметь обрабатывать с помощью вычислительной техники с целью извлечения знаний.
Статистическое моделирование и интеллектуальный анализ данных представляют необходимые инструменты и способы обработки и анализа больших объемов данных.
В данном дипломном проекте рассматривается один из способов информационно"=статистического  моделирования "--- вероятностные сети, в частности, байесовы сети доверия.

Байесовы сети применяются для решения различных практических задач.
Вероятностная природа сетей способствует их успешному применению для создания различных экспертных систем.
Одним из первых практических проектов, использующих байесовы сети, стала система медицинской диагностики PathFinder-4~\cite{terehov_2003}.
В прикладном программном обеспечении байесовы сети используются в различных пошаговых мастерах по диагностике неисправностей, исправлению ошибок, консультированию пользователей, например, диагностика неисправности оборудования в Windows~\cite{terehov_2003}.
Вероятностные сети применимы также для создания рекомендательных систем, основанных на предпочтениях пользователя и истории его активности.

Важным этапом в применении вероятностных сетей для решения какой"=либо задачи является, собственно, её построение, а именно задание структуры сети.
Под структурой понимается задание отношений независимости между парами вершин, которые соответствуют случайным величинам из исходной задачи.

Исторически одним из первых способов построения структуры байесовых сетей было привлечение экспертов в конкретной предметной области и разработка архитектуры сети в соответствии с представлением экспертов о решаемой задаче и предметной области.
Данный способ имеет ряд очевидных недостатков: необходимость привлечения экспертов; большая трудоемкость процесса построения сети для сложных задач с большим количеством случайных величин и, соответственно, большим количеством узлов; ограниченность модели представлением эксперта о задаче и предметной области.

Появляются новые предметные области и классы задач, в которых довольно сложно найти признанного эксперта.
В такой ситуации становится понятным, что привлечение эксперта для разработки байесовой сети не всегда возможно и расточительно по времени.
С другой стороны, сбор экспериментальных данных для решения какой"=либо задачи обычно легко доступен.
В связи с этим возникает задача обработки этих данных для решения задачи.

В данном дипломном проекте рассматривается задача вывода структуры вероятностной сети по набору экспериментальных данных.
С учетом приведённых выше утверждений про потенциальную невозможность привлечения экспертов и доступность экспериментальных данных, умение строить сеть лишь по набору экспериментальных данных становится очень привлекательным.
Помимо ускорения процесса построения сети, автоматический вывод структуры имеет ряд дополнительных преимуществ перед <<ручным>>: становится возможным выявление ранее неизвестных зависимостей между переменными в известных и новых предметных областях; появляется возможность довольно легко обновлять структуру при получении более достоверных экспериментальных данных; создание и применение вероятностных сетей становится более доступным для не"=экспертов, и появляется возможность использования вероятностного подхода для решения б\'{о}льшего множества прикладных задач.

Не смотря на привлекательность автоматического построения структуры сети, вычислительно эта задача является $\mathcal{NP}$-полной~\cite{Chickering96learningbayesian}.
Многие существующие алгоритмы состоят из двух компонентов\ignore{%
В математике принято считать слово "компонента" женского рода, соответственно мн.ч. р.п будет "компонент", в других областях - компонент, сущ. м.р., во мн.ч. р.п. - компонентов. Источник http://bit.ly/10PMCfI и http://bit.ly/11Rsj85}: функции для оценки качества сети для имеющихся экспериментальных данных и процедуры поиска структуры сети, оптимизирующую выбранную оценочную функцию.
Во многих алгоритмах точное вычисление оценочной функции имеет экспоненциальную сложность по времени, но на практике с помощью различных допущений и оптимизаций её можно аппроксимировать за приемлемое время.
Пространство же возможных направленных ациклических графов имеет супер"=экспоненциальный порядок роста~\cite{robinson_1977}, и полный перебор в таком пространстве возможных решений на практике не возможен для задач с более чем семью наблюдаемыми случайными величинами.

На практике применяют несколько различных способов уменьшения пространства возможных решений, некоторые из них предполагают проведение предварительных вычислений для извлечения первичной информации о взаимоотношениях переменных, другие "--- требуют априорных знаний об исходном распределении и частичных знаний о зависимостях переменных.
Естественно подобные ухищрения в различной степени влияют на качество получаемого результата не в лучшую сторону, но зато позволяют существенно сократить пространство поиска, что в свою очередь позволяет в разумное время найти структуру сети, которая будет аппроксимировать <<истинное>> распределение из которого были получены экспериментальные данные.

В данном дипломном проекте реализуются некоторые из известных алгоритмов автоматического вывода структуры сети по данным, дополнительно производятся некоторые оптимизации и улучшения в части их реализации. 
Также были произведены экспериментальные модификации этих алгоритмов для улучшения качества выводимой сети. 
В результате получилась библиотека классов для платформы \dotnet{}, написанная на языках программирования \csharp{} и \fsharp{}, пригодная для решения практических задач в реальных проектах.
На данный момент в библиотеке реализована лишь возможность построить структуру сети по данным, но не затронуты очень важные и интересные вопросы, такие как обучение параметров сети и задача статистического вывода суждений в обученной сети.
